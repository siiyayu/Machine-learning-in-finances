{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом блоке мы познакомимся с практическим применением гауссовских процессов на примере прогнозирования финансового ряда. Сначала построим нелинейный тренд. А потом по аналогии, в качестве задания предлагается добавить сезонную компоненту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки регрессии на гауссовских процессах существуют специализированные пакеты, одни из самых популярных - GPy на языке Python, GPML на Matlab, GPFlow на TensorFLow.\n",
    "Но для лучшего понимания математики, в учебных целях, - мы построим прогноз на вероятностном языке моделирования stan, где пропишем регрессию в виде формул. Stan - высокопроизводительный фреймворк для байесовских моделей и не только. На нем удобно сформулировать модель в виде уравнений, и далее программа методом точечной оптимизации, MCMC, или Variational Inference  оценивает параметры с высокой производительностью.  От конкурентов его отличает очень хорошая реализация алгоритма HMC (Hamilton Markov Chain). Подробнее о Stan - https://mc-stan.org/users/documentation/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan #интерфейc stan в питоне\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "timeSeries = pd.read_csv('data.csv',sep = ';',decimal=',')[\"x\"] # пример финансового временного ряда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте спрогнозируем данный временной ряд. Первые 730 точек (2 года) будут использоваться для обучения. А прогноз будем строить на последних 365 точек.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим файл с кодом на языке stan. Подробно про язык Stan смотрите в приложении \"stan-manual.pdf\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile GaussianProcess.stan \n",
    "\n",
    "//определяется тип данных\n",
    "data {\n",
    "    int N1;        //число наблюдений в обучающей выборке\n",
    "    real x1[N1];   //факторы - в нашем случае время\n",
    "    vector[N1] y1; //наблюдаемые величины в обучающей выборке\n",
    "    int N2;        //число наблюдений в тестовой выборке\n",
    "    real x2[N2];   //факторы на тестовой выборке - в нашем случае время в будущем  \n",
    "}\n",
    "\n",
    "//генерируются данные внутри программы, или обрабатывается, то что определено в блоке data\n",
    "transformed data{ \n",
    "    vector[N1] mu = rep_vector(.0, N1); //нулевой уровень, вокруг которого строится гауссовский процесс\n",
    "}\n",
    "\n",
    "\n",
    "//параметры модели, - в нашем случае гиперпараметры ядра\n",
    "parameters {              //параметры ядра\n",
    "    real<lower=0> a;      //амплитуда RBF ядра\n",
    "    real<lower=0> l;      //эффективная длина RBF ядра\n",
    "    real<lower=0> sigma;  //ошибка регрессии\n",
    "    \n",
    "}\n",
    "\n",
    "//параметры могут обрабатываться\n",
    "transformed parameters{\n",
    "    matrix[N1,N1] K; //матрица ковариации для обучающей выборки\n",
    "    \n",
    "    for (i in 2:N1)\n",
    "        for(j in 1:(i-1))\n",
    "        {\n",
    "            K[i,j] = square(a) * exp(-square(x1[i]-x1[j])*inv_square(l*365)*0.5 );\n",
    "            K[j,i] = K[i,j]; // делаем ее симметричной\n",
    "        }\n",
    "    \n",
    "    for (n in 1:N1)\n",
    "        K[n,n] = square(a) +\n",
    "                 square(sigma) +   \n",
    "                 1e-12;    // слагаемое для того, чтобы матрица всегда оставалась положительно определенной на этапе оптимизации\n",
    "}\n",
    "\n",
    "// В этом блоке связываются параметры и данные через распределения. Stan авто-\n",
    "// матически строит функции правдоподобия и оптимизирует параметры распределения. \n",
    "// Дополнительно, можно добавлять приорные распределения для параметров модели\n",
    "model { \n",
    "    \n",
    "      \n",
    "    \n",
    "    y1 ~ multi_normal(rep_vector(0,N1),K); \n",
    "    \n",
    "    \n",
    "    a ~ normal(0, 1);  //приорное распределение магнитуды колебания ряда\n",
    "    l ~ lognormal(2, .1); // приорное распределение эф. длины\n",
    "                          // нас интересует глобальный тренд, поэтому мы определили распределение подальше от нуля. \n",
    "                          // приорные распределения выставляются на \"глаз\", чтобы подсказать оптимизатору какого порядка должны быть параметры\n",
    "    \n",
    "}\n",
    "\n",
    "//В блоке генерируются значения на основе оцененных параметров\n",
    "\n",
    "generated quantities{\n",
    "matrix[N2,N1] Kstar; //матрица ковариации между факторами прогнозными и факторами обучающими\n",
    "vector[N2] yforecasted; //прогноз\n",
    "    for (i in 1:N2)\n",
    "        for(j in 1:N1)\n",
    "            Kstar[i,j] = square(a) * exp(-square(x2[i]-x1[j]) * inv_square(l*365) * 0.5);\n",
    "    \n",
    "yforecasted = Kstar * (K\\y1); //предскажем прогнозное среднее    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код модели в Stan компилируется в машинный код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CompiledModel =  pystan.StanModel(file='GaussianProcess.stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения будем использовать 730 (2 года) наблюдений. Построим долгосрочный тренд "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalNumberOfObs = len(timeSeries)\n",
    "numberForLearning = 730 #два года \n",
    "\n",
    "inputDataForStan = {\n",
    "    'N1' : numberForLearning,\n",
    "    'x1' : range(0,numberForLearning),\n",
    "    'y1' : timeSeries[0:numberForLearning],\n",
    "    'N2' : totalNumberOfObs, #прогноз будет по\n",
    "    'x2' : range(0,totalNumberOfObs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим значения оптимальных параметров, согласно спецификации модели определенной в stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized = CompiledModel.optimizing(data = inputDataForStan)\n",
    "yforecasted = optimized[\"yforecasted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слева от вертикальной линии - обучающая выборка. Справа будущее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yforecasted,'blue' ) \n",
    "plt.plot(timeSeries, 'grey')\n",
    "plt.axvline(x=730)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание:\n",
    "Добавьте в файле stan слагаемое к ядру, отвечающее за сезонность.  \n",
    "Используйте периодическое ядро с периодом 365 дней (год). Поиграйтесь с\n",
    "параметром эффективной длины в периодическом ядре: чем меньше параметр, -  тем лучше\n",
    "улавливается помесячная сезонность. \n",
    "\n",
    "В языке stan число пи - pi()\n",
    "\n",
    "Stan manual - https://github.com/stan-dev/stan/releases/download/v2.17.1/stan-reference-2.17.1.pdf\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "Снова скомпилируйте файл - и постройте бэктест.\n",
    "        \n",
    "По поводу формы периодического ядра смотрите лекцию, или: \n",
    "\n",
    "https://www.cs.toronto.edu/~duvenaud/cookbook/\n",
    "    \n",
    "http://www.gaussianprocess.org/gpml/chapters/RW.pdf    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile GaussianProcessSeason.stan \n",
    "\n",
    "//определяется тип данных\n",
    "data {\n",
    "    int N1;        //число наблюдений в обучающей выборке\n",
    "    real x1[N1];   //факторы - в нашем случае время\n",
    "    vector[N1] y1; //наблюдаемые величины в обучающей выборке\n",
    "    int N2;        //число наблюдений в тестовой выборке\n",
    "    real x2[N2];   //факторы на тестовой выборке - в нашем случае время в будущем  \n",
    "}\n",
    "\n",
    "//генерируются данные внутри программы, или обрабатывается, то что определено в блоке data\n",
    "transformed data{ \n",
    "    vector[N1] mu = rep_vector(.0, N1); //нулевой уровень, вокруг которого строится гауссовский процесс\n",
    "}\n",
    "\n",
    "\n",
    "//параметры модели, - в нашем случае гиперпараметры ядра\n",
    "parameters {              //параметры ядра\n",
    "    real<lower=0> a;      //амплитуда RBF ядра\n",
    "    real<lower=0> l;      //эффективная длина RBF ядра\n",
    "    real<lower=0> sigma;  //ошибка регрессии\n",
    "    real<lower=0> b;      //амплитуда периодического ядра\n",
    "    \n",
    "}\n",
    "\n",
    "//параметры могут обрабатываться\n",
    "transformed parameters{\n",
    "    matrix[N1,N1] K; //матрица ковариации для обучающей выборки\n",
    "    \n",
    "    for (i in 2:N1)\n",
    "        for(j in 1:(i-1))\n",
    "        {\n",
    "            K[i,j] = square(a) * exp(-square(x1[i]-x1[j])*inv_square(l*365)*0.5 ) + \n",
    "            \n",
    "            \n",
    "//-------------------------Дописать cлагаемое--------------------------------------\n",
    "            \n",
    "           square(b)*\n",
    "\n",
    "//-----------------------------------------------------------------------\n",
    "            \n",
    "            \n",
    "            K[j,i] = K[i,j];\n",
    "        }\n",
    "    \n",
    "    for (n in 1:N1)\n",
    "        K[n,n] = square(a) +\n",
    "                 square(b) +   \n",
    "                 square(sigma) +   \n",
    "                 1e-12;    // слагаемое для того, чтобы матрица всегда оставалась положительно определенной на этапе оптимизации\n",
    "}\n",
    "\n",
    "// В этом блоке связываются параметры и данные через распределения. Stan авто-\n",
    "// матически строит функции правдоподобия и оптимизирует параметры распределения. \n",
    "// Дополнительно, можно добавлять приорные распределения для параметров модели\n",
    "model { \n",
    "    \n",
    "      \n",
    "    \n",
    "    y1 ~ multi_normal(rep_vector(0,N1),K); \n",
    "    \n",
    "    b ~ normal(0, 1);\n",
    "    a ~ normal(0, 1);  //приорное распределение магнитуды колебания ряда\n",
    "    l ~ lognormal(2, .1); // приорное распределение эф. длины\n",
    "                          // нас интересует глобальный тренд, поэтому мы определили распределение подальше от нуля. \n",
    "                    \n",
    "    \n",
    "}\n",
    "\n",
    "//в блоке генерируются значения на основе оцененных параметров\n",
    "\n",
    "generated quantities{\n",
    "matrix[N2,N1] Kstar; //матрица ковариации между факторами прогнозными и факторами обучающими\n",
    "vector[N2] yforecasted; //прогноз\n",
    "    for (i in 1:N2)\n",
    "        for(j in 1:N1)\n",
    "            Kstar[i,j] = square(a) * exp(-square(x2[i]-x1[j]) * inv_square(l*365) * 0.5)+\n",
    "    \n",
    "//-------------------------------аналогичное слагаемое здесь------------------\n",
    "    \n",
    "      square(b)*\n",
    "   \n",
    "//-----------------------------------------------------------------------------\n",
    "yforecasted = Kstar * (K\\y1);    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompiledModel2 =  pystan.StanModel(file='GaussianProcessSeason.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized = CompiledModel2.optimizing(data = inputDataForStan)\n",
    "yforecasted = optimized[\"yforecasted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yforecasted,'blue' ) \n",
    "plt.plot(timeSeries, 'grey')\n",
    "plt.axvline(x=730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yforecasted[-365:],'blue' ) \n",
    "plt.plot(timeSeries[-365:].values,'grey')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на адекватность прогноза. Для \"хорошего рисунка\" пусть ошибка прогноза будет не выше 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((yforecasted[-365:] - timeSeries[-365:])**2)) < 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
